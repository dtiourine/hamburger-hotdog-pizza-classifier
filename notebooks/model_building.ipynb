{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T15:46:49.950777Z",
     "start_time": "2024-06-19T15:46:49.947018Z"
    }
   },
   "source": [
    "# Import packages\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.config import PROCESSED_DATA_DIR, RAW_DATA_DIR\n",
    "image_path = RAW_DATA_DIR\n",
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:46:50.453756Z",
     "start_time": "2024-06-19T15:46:50.449851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config_path = 'params.json'\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "print(json.dumps(config, indent=2))"
   ],
   "id": "cc3123caabef7803",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_params\": {\n",
      "    \"learning_rate\": 0.001,\n",
      "    \"batch_size\": 64,\n",
      "    \"num_epochs\": 25,\n",
      "    \"dropout_rate\": 0.3,\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"loss_function\": \"categorical_crossentropy\",\n",
      "    \"metrics\": [\n",
      "      \"accuracy\"\n",
      "    ],\n",
      "    \"output_shape\": 3\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:46:50.908354Z",
     "start_time": "2024-06-19T15:46:50.905548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load hyperparams from params.json\n",
    "\n",
    "learning_rate = config['model_params']['learning_rate']\n",
    "batch_size = config['model_params']['batch_size']\n",
    "num_epochs = config['model_params']['num_epochs']\n",
    "dropout_rate = config['model_params']['dropout_rate']\n",
    "optimizer = config['model_params']['optimizer']\n",
    "loss_function = config['model_params']['loss_function']\n",
    "metrics = config['model_params']['metrics']\n",
    "output_shape = config['model_params']['output_shape']"
   ],
   "id": "c56836a1b80282c0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:46:51.287641Z",
     "start_time": "2024-06-19T15:46:51.275629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare data into dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = ImageFolder(train_dir, transform=transform)\n",
    "test_data = ImageFolder(test_dir, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ],
   "id": "f8ef72168ffb3d9d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:56:49.310119Z",
     "start_time": "2024-06-19T15:56:49.305978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HHP01(nn.Module):\n",
    "    def __init__(self, input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super(HHP01, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*53*53, out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = self.conv_block1(x)\n",
    "        # print(x.shape)\n",
    "        # x = self.conv_block2(x)\n",
    "        # print(x.shape)\n",
    "        # x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        # return x\n",
    "        return self.classifier(self.conv_block2(self.conv_block1(x)))"
   ],
   "id": "5e75b72efb2c6750",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:56:49.650976Z",
     "start_time": "2024-06-19T15:56:49.645626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HHP01(input_shape=3, hidden_units=10, output_shape=output_shape).to(device)\n",
    "model"
   ],
   "id": "3d00a6052fada4d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HHP01(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=28090, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:56:50.220611Z",
     "start_time": "2024-06-19T15:56:50.043651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_batch, label_batch = next(iter(train_loader))\n",
    "image_batch.shape, label_batch.shape"
   ],
   "id": "27d0d3d23db0a120",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 224, 224]), torch.Size([64]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:56:50.662049Z",
     "start_time": "2024-06-19T15:56:50.637801Z"
    }
   },
   "cell_type": "code",
   "source": "model(image_batch.to(device))",
   "id": "d0cfa414c588547b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0072,  0.0450, -0.0343],\n",
       "        [-0.0018,  0.0472, -0.0380],\n",
       "        [-0.0064,  0.0504, -0.0319],\n",
       "        [-0.0003,  0.0459, -0.0383],\n",
       "        [-0.0059,  0.0510, -0.0324],\n",
       "        [-0.0002,  0.0469, -0.0318],\n",
       "        [-0.0043,  0.0475, -0.0335],\n",
       "        [-0.0044,  0.0438, -0.0396],\n",
       "        [ 0.0016,  0.0399, -0.0409],\n",
       "        [-0.0072,  0.0410, -0.0318],\n",
       "        [-0.0040,  0.0470, -0.0395],\n",
       "        [-0.0062,  0.0493, -0.0357],\n",
       "        [ 0.0008,  0.0460, -0.0392],\n",
       "        [-0.0049,  0.0503, -0.0334],\n",
       "        [-0.0058,  0.0505, -0.0313],\n",
       "        [-0.0063,  0.0511, -0.0374],\n",
       "        [-0.0062,  0.0477, -0.0384],\n",
       "        [-0.0034,  0.0455, -0.0342],\n",
       "        [-0.0066,  0.0394, -0.0365],\n",
       "        [-0.0042,  0.0471, -0.0350],\n",
       "        [-0.0040,  0.0503, -0.0433],\n",
       "        [-0.0055,  0.0429, -0.0398],\n",
       "        [-0.0031,  0.0488, -0.0339],\n",
       "        [-0.0044,  0.0483, -0.0386],\n",
       "        [-0.0003,  0.0447, -0.0417],\n",
       "        [-0.0104,  0.0536, -0.0320],\n",
       "        [-0.0114,  0.0469, -0.0358],\n",
       "        [-0.0071,  0.0414, -0.0384],\n",
       "        [-0.0098,  0.0434, -0.0322],\n",
       "        [-0.0039,  0.0540, -0.0392],\n",
       "        [-0.0031,  0.0486, -0.0386],\n",
       "        [-0.0048,  0.0467, -0.0394],\n",
       "        [-0.0080,  0.0566, -0.0387],\n",
       "        [-0.0036,  0.0430, -0.0402],\n",
       "        [-0.0079,  0.0479, -0.0341],\n",
       "        [-0.0041,  0.0455, -0.0319],\n",
       "        [ 0.0003,  0.0461, -0.0380],\n",
       "        [-0.0047,  0.0415, -0.0360],\n",
       "        [-0.0027,  0.0459, -0.0360],\n",
       "        [-0.0034,  0.0477, -0.0426],\n",
       "        [-0.0011,  0.0468, -0.0379],\n",
       "        [-0.0074,  0.0458, -0.0358],\n",
       "        [-0.0049,  0.0439, -0.0405],\n",
       "        [-0.0088,  0.0530, -0.0339],\n",
       "        [ 0.0007,  0.0444, -0.0366],\n",
       "        [-0.0025,  0.0433, -0.0338],\n",
       "        [-0.0011,  0.0460, -0.0397],\n",
       "        [-0.0045,  0.0460, -0.0374],\n",
       "        [-0.0119,  0.0513, -0.0319],\n",
       "        [-0.0092,  0.0518, -0.0307],\n",
       "        [-0.0053,  0.0430, -0.0274],\n",
       "        [-0.0077,  0.0518, -0.0363],\n",
       "        [-0.0088,  0.0554, -0.0372],\n",
       "        [-0.0015,  0.0426, -0.0404],\n",
       "        [-0.0125,  0.0525, -0.0420],\n",
       "        [-0.0070,  0.0526, -0.0296],\n",
       "        [-0.0047,  0.0454, -0.0420],\n",
       "        [-0.0078,  0.0510, -0.0386],\n",
       "        [-0.0057,  0.0408, -0.0430],\n",
       "        [-0.0045,  0.0485, -0.0386],\n",
       "        [-0.0060,  0.0517, -0.0412],\n",
       "        [-0.0065,  0.0474, -0.0328],\n",
       "        [-0.0057,  0.0460, -0.0369],\n",
       "        [-0.0045,  0.0432, -0.0287]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T15:56:51.176897Z",
     "start_time": "2024-06-19T15:56:51.171256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model, input_size=(1, 3, 224, 224))"
   ],
   "id": "b9de75815fa96a62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "HHP01                                    [1, 3]                    --\n",
       "├─Sequential: 1-1                        [1, 10, 110, 110]         --\n",
       "│    └─Conv2d: 2-1                       [1, 10, 222, 222]         280\n",
       "│    └─ReLU: 2-2                         [1, 10, 222, 222]         --\n",
       "│    └─Conv2d: 2-3                       [1, 10, 220, 220]         910\n",
       "│    └─MaxPool2d: 2-4                    [1, 10, 110, 110]         --\n",
       "├─Sequential: 1-2                        [1, 10, 53, 53]           --\n",
       "│    └─Conv2d: 2-5                       [1, 10, 108, 108]         910\n",
       "│    └─ReLU: 2-6                         [1, 10, 108, 108]         --\n",
       "│    └─Conv2d: 2-7                       [1, 10, 106, 106]         910\n",
       "│    └─MaxPool2d: 2-8                    [1, 10, 53, 53]           --\n",
       "├─Sequential: 1-3                        [1, 3]                    --\n",
       "│    └─Flatten: 2-9                      [1, 28090]                --\n",
       "│    └─Linear: 2-10                      [1, 3]                    84,273\n",
       "==========================================================================================\n",
       "Total params: 87,283\n",
       "Trainable params: 87,283\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 78.77\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 9.65\n",
       "Params size (MB): 0.35\n",
       "Estimated Total Size (MB): 10.60\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T16:02:54.131633Z",
     "start_time": "2024-06-19T16:01:54.112163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_model(num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "# Call the training function\n",
    "train_model(10)"
   ],
   "id": "37a0a9d36f35881e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0986, Accuracy: 34.67%\n",
      "Epoch 2, Loss: 1.0956, Accuracy: 35.73%\n",
      "Epoch 3, Loss: 1.0883, Accuracy: 40.58%\n",
      "Epoch 4, Loss: 1.0745, Accuracy: 42.40%\n",
      "Epoch 5, Loss: 1.0470, Accuracy: 46.93%\n",
      "Epoch 6, Loss: 1.0280, Accuracy: 47.33%\n",
      "Epoch 7, Loss: 1.0042, Accuracy: 49.69%\n",
      "Epoch 8, Loss: 0.9870, Accuracy: 51.42%\n",
      "Epoch 9, Loss: 0.9710, Accuracy: 53.16%\n",
      "Epoch 10, Loss: 0.9610, Accuracy: 53.42%\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f5635c4c03da4fcc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
